{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./datasets',train=True,download=True,transform=transforms.ToTensor())\n",
    "testset = torchvision.datasets.CIFAR10(root='./datasets',train=False,download=True,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches\n",
    "trainloader = torch.utils.daa.DataLoader(trainset,\n",
    "                                        batch_size = 8,\n",
    "                                        shuffle = True,\n",
    "                                        num_workers=2)\n",
    "testloader = torch.utils.daa.DataLoader(testset,\n",
    "                                        batch_size = 8,\n",
    "                                        shuffle = False,\n",
    "                                        num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore data\n",
    "\n",
    "# loading batches\n",
    "images_batch, labels_batch = iter(trainloader).next()\n",
    "\n",
    "# to use matplotlib\n",
    "img = torchvision.utils.make_grid(images_batch)\n",
    "plt.imgshow(np.transpose(img, (1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = 3\n",
    "hid = 16\n",
    "hid2 = 32\n",
    "out = len(labels)\n",
    "k_conv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(inp, hid, k_conv),\n",
    "            nn.BatchNorm2(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(hid, hid2, k_conv),\n",
    "            nn.BatchNorm2(hid2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        # pooling layers do not change number of input features\n",
    "        self.fc = nn.Linear(hid2 * k_conv * k_conv, out)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "total_step = len(trainloader)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (image,labels) in enumerate(trainloader):\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2000 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss:  {:.4f}'\\\n",
    "                 .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images)\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "    print('Accuracy of the model on 10k test images: {}%'\\\n",
    "         .format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusing train neurla network - saves time and effort of re training from scratch\n",
    "# only makes sense for similar problems\n",
    "\n",
    "# freeze lower layers (lower layers focus on feature extraction) and retrain only using higher layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet-18 pretrained model\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# from docu: images fed to pre-trained model have to be normalized using some sort of pre determined parameters\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip = zipfile.Zipfile('datasets/flowers_.zip')\n",
    "zip.extractall('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'datasets/flowers_'\n",
    "\n",
    "images_datasets = {}\n",
    "images_datasets['train'] = datasets.ImageFolder(data_dif+'/train',train_transform)\n",
    "images_datasets['test'] = datasets.ImageFolder(data_dif+'/test',train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = images_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "\n",
    "dataloaders['train'] = torch.utils.daa.DataLoader(image_dataset['train'],\n",
    "                                        batch_size = 8,\n",
    "                                        shuffle = True,\n",
    "                                        num_workers=2)\n",
    "dataloaders['test'] = torch.utils.daa.DataLoader(image_dataset['test'],\n",
    "                                        batch_size = 8,\n",
    "                                        shuffle = False,\n",
    "                                        num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "np.clip(inp,0,1).max()\n",
    "inp.numpy().transpose((1,2,0)).shape\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(inp,title=None):\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    inp= std*inp+mean\n",
    "    inp = np.clip(inp,0,1)\n",
    "    \n",
    "    plt.figure(figsize = (16,4))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "        img_show(inp, title = [class_names[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make our own linear layer -- get final number of input features that we need to pass into our last linear layer\n",
    "num_ftrs = model.fc.in_features\n",
    "num_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "# decays learning rate as we get close to convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Lineaer(num_ftrs,5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                     lr = 0.001,\n",
    "                     momentum=0.9)\n",
    "\n",
    "sched = lr_scheduler.StepLR(optimizer,\n",
    "                           step_size = 7,\n",
    "                           gamma = 0.1) # reduce learning rate by 0.1 every 7 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(phase, running_loss, running_corrects):\n",
    "    epoch_loss = running_loss/len(image_datasets[phase])\n",
    "    epoch_acc = running_corrects.double()/len(image-Datasets[phase])\n",
    "    \n",
    "    print('{} Loss: {:.4f} acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def phase_train(model, criterion, optimizer, scheduler):\n",
    "    scheduler.step()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            _,preds = torch.max(outputs,1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    calculate_accuracy('train', running_loss, running_corrects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_test(model, criterion, optimizer):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    global best_acc\n",
    "    \n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            loss = criterion(outputs,labels)\n",
    "            \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epochLoss, epoc_acc = cauclate_accuracy('test',running_loss, running_corrects)\n",
    "    \n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    return best_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "\n",
    "def build_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-'*10)\n",
    "        \n",
    "        phase_train(model, criterion, optimizer, scheduler)\n",
    "        best_model_wts = phase_test(model,criterion,optimizer)\n",
    "        print()\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(model,\n",
    "                   criterion,\n",
    "                   optimizer,\n",
    "                   sched,\n",
    "                   num_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs,labels = iter(dataloaders['test']).next()\n",
    "    inp = torchvision.utils.make_grid(inputs)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    _,preds = torch.max(outputs, 1)\n",
    "    \n",
    "    for j in range(len(inputs)):\n",
    "        inp = inputs.data[j]\n",
    "        img_show(inp, 'predicted:' + class_names[preds[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfer learning using frozen layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in frozen_model.parameters():\n",
    "    param_requres_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_model.fc = nn.Linear(num_ftrs, 5)\n",
    "\n",
    "optimizer = optim.SGD(frozen_model.fc.parameters(),\n",
    "                     lr = 0.001,\n",
    "                     momentum=0.9)\n",
    "\n",
    "sched = lr_scheduler.StepLR(optimizer,\n",
    "                           step_size = 7\n",
    "                           gamma = 0.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_model = build_model(frozen_model,\n",
    "                          criterion,\n",
    "                          optimizer\n",
    "                          sched\n",
    "                          num_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs,labels = iter(dataloaders['test']).next()\n",
    "    inp = torchvision.utils.make_grid(inputs)\n",
    "    \n",
    "    outputs = frozen_model(inputs)\n",
    "    _,preds = torch.max(outputs, 1)\n",
    "    \n",
    "    for j in range(len(inputs)):\n",
    "        inp = inputs.data[j]\n",
    "        img_show(inp, 'predicted:' + class_names[preds[j]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
